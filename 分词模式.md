分词模式


【全模式】：我/ 来到/ 北京/ 清华/ 清华大学/ 华大/ 大学
【精确模式】：我/ 来到/ 北京/ 清华大学
【新词识别】：他/ 来到/ 了/ 网易/ 杭研/ 大厦
【搜索引擎模式】：小明/ 硕士/ 毕业/ 于/ 中国/ 科学/ 学院/ 科学院/ 中国科学院/ 计算/ 计算所/ ，/ 后/ 在/ 日本/ 京都/ 大学/ 日本京都大学/ 深造
【歧义消除】：结过婚/ 的/ 和/ 尚未/ 结过婚/ 的

持三种分词模式：
精确模式，试图将句子最精确地切开，适合文本分析；
全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义。具体来说，分词过程不会借助于词频查找最大概率路径，亦不会使用HMM；
搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。
支持添加自定义词典和自定义词

10. 命令行分词

Segmenter.Cli项目build之后得到jiebanet.ext，它的选项和实例用法如下：
-f       --file          the file name, (必要的).
-d       --delimiter     the delimiter between tokens, default: / .
-a       --cut-all       use cut_all mode.
-n       --no-hmm        don't use HMM.-p       --pos           enable POS tagging.-v       --version       show version info.-h       --help          show help details.sample usages:$ jiebanet -f input.txt > output.txt$ jiebanet -d | -f input.txt > output.txt$ jiebanet -p -f input.txt > output.txt



地址词
商家 商品

